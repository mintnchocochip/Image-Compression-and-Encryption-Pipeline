import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from io import BytesIO
import time
import math
from skimage.metrics import mean_squared_error as mse
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
from skimage.measure import shannon_entropy
import hashlib
import warnings
import os # For path manipulation if needed
import base64 # For potential data URI download links
import zlib # <--- Added for compression
import traceback # <--- Added for detailed error reporting

# --- Environment Specific Imports ---
try:
    from google.colab import files
    ENV = 'colab'
except ImportError:
    print("Not running in Google Colab. File upload/download will require manual steps or alternative libraries (like ipywidgets).")
    # Try importing tools for Jupyter download links
    try:
        from IPython.display import display, HTML
        import ipywidgets as widgets # Import for potential widget-based upload in Jupyter
        ENV = 'jupyter'
    except ImportError:
        print("IPython/ipywidgets not available. Download links may not be generated automatically.")
        ENV = 'other'


# Ignore specific warnings from skimage and PIL
warnings.filterwarnings("ignore", category=UserWarning, module='skimage')
warnings.filterwarnings("ignore", category=UserWarning, module='PIL')
warnings.filterwarnings("ignore", category=FutureWarning, module='skimage')


# %% [markdown]
# ## Task 1: Image Preprocessing (Adapted for Uploaded Data)

# %%
def preprocess_image(img_input, target_size=None, grayscale=False, simulate_low_bandwidth=False, low_bw_size=(128, 128)):
    """Loads image from various inputs, converts, optionally resizes and pads."""
    try:
        if isinstance(img_input, (BytesIO, bytes)):
            # If input is bytes, wrap it in BytesIO
            if isinstance(img_input, bytes):
                img_input = BytesIO(img_input)
            img_input.seek(0) # Ensure reading from the start for BytesIO
            img = Image.open(img_input)
            print("Loaded image from uploaded data.")
        elif isinstance(img_input, str): # Keep URL/Path option as fallback
            # Basic check for URL (could be more robust)
            if img_input.startswith('http://') or img_input.startswith('https://'):
                 # If you need URL loading again, uncomment the next lines and import requests
                 # import requests
                 # response = requests.get(img_input)
                 # response.raise_for_status()
                 # img = Image.open(BytesIO(response.content))
                 # print(f"Loaded image from URL: {img_input}")
                 raise NotImplementedError("URL loading currently disabled. Upload file or use local path.")
            else:
                 img = Image.open(img_input)
                 print(f"Loaded image from Path: {img_input}")
        elif isinstance(img_input, Image.Image):
            img = img_input
            print("Processing provided PIL image object.")
        elif img_input is None: # Handle case where no input was provided (e.g., upload failed)
             raise ValueError("No valid image input provided.")
        else:
             raise ValueError(f"Unsupported input type for preprocess_image: {type(img_input)}")

    except FileNotFoundError:
        print(f"Error: File not found at path '{img_input}'.")
        print("Using a fallback procedural image.")
        img_array = np.zeros((256, 256, 3), dtype=np.uint8)
        img_array[:, :, 0] = np.linspace(0, 255, 256) # Red gradient
        img_array[:, :, 1] = np.linspace(0, 255, 256).T # Green gradient
        img_array[:, :, 2] = 128 # Blue constant
        img = Image.fromarray(img_array)
    except Exception as e:
        print(f"Error loading image: {e}")
        # Fallback to a default procedural image if loading fails
        print("Using a fallback procedural image.")
        img_array = np.zeros((256, 256, 3), dtype=np.uint8)
        img_array[:, :, 0] = np.linspace(0, 255, 256) # Red gradient
        img_array[:, :, 1] = np.linspace(0, 255, 256).T # Green gradient
        img_array[:, :, 2] = 128 # Blue constant
        img = Image.fromarray(img_array)


    original_mode = img.mode
    original_size_before_processing = img.size
    print(f"Original image mode: {original_mode}, size: {original_size_before_processing}")

    if grayscale and img.mode != 'L':
        img = img.convert('L')
        print(f"Converted to grayscale. New mode: {img.mode}")
    elif not grayscale and img.mode not in ['RGB', 'RGBA']:
         print(f"Converting mode {img.mode} to RGB for consistency.")
         img = img.convert('RGB')

    if img.mode == 'RGBA':
        print("Converting RGBA to RGB by blending onto a white background.")
        # Create a white background image
        bg = Image.new("RGB", img.size, (255, 255, 255))
        # Paste the RGBA image onto the white background using the alpha channel as mask
        try:
            # This assumes the alpha channel is the 4th channel
            bg.paste(img, mask=img.split()[3])
        except IndexError:
             print("Warning: Could not get alpha channel for RGBA conversion. Using image directly.")
             bg.paste(img) # Paste without mask if alpha split fails
        img = bg # Use the blended image

    # Dynamic resizing
    if simulate_low_bandwidth:
        print(f"Simulating low bandwidth. Resizing image to {low_bw_size}...")
        img = img.resize(low_bw_size, Image.Resampling.LANCZOS)
        print(f"Resized image size: {img.size}")
    elif target_size:
        # Ensure target_size is a tuple (width, height)
        if isinstance(target_size, (list, tuple)) and len(target_size) == 2:
            print(f"Resizing image to {target_size}...")
            img = img.resize(target_size, Image.Resampling.LANCZOS)
            print(f"Resized image size: {img.size}")
        else:
            print(f"Warning: Invalid target_size {target_size}. Skipping resize.")


    img_array = np.array(img, dtype=np.uint8)

    # Padding to square shape (required for ACM)
    h, w = img_array.shape[:2]
    padded = False
    if h != w:
        padded = True
        print(f"Image is not square ({h}x{w}). Padding to make it square.")
        max_dim = max(h, w)
        pad_h = max_dim - h
        pad_w = max_dim - w
        # Calculate padding amounts for top, bottom, left, right
        # np.pad format: ((before_axis1, after_axis1), (before_axis2, after_axis2), ...)
        if img_array.ndim == 3: # Color image
            # ((top, bottom), (left, right), (channel_pad_before, channel_pad_after))
            pad_width = ((pad_h // 2, pad_h - pad_h // 2), (pad_w // 2, pad_w - pad_w // 2), (0, 0))
        else: # Grayscale image
            # ((top, bottom), (left, right))
            pad_width = ((pad_h // 2, pad_h - pad_h // 2), (pad_w // 2, pad_w - pad_w // 2))
        # Pad with constant value 0 (black)
        img_array = np.pad(img_array, pad_width, mode='constant', constant_values=0)
        print(f"Padded image size: {img_array.shape[:2]}")

    # Return the processed (potentially padded) array, the original size *before padding*, and the padding flag
    return img_array, original_size_before_processing, padded


# %% [markdown]
# ## Task 2: Encryption (Core Logic - ACM + Logistic Map)

# %%
# --- Arnold's Cat Map ---
def arnold_cat_map(img_array, iterations, a=1, b=1):
    """Applies Arnold's Cat Map for pixel shuffling."""
    if img_array.ndim not in [2, 3]:
        raise ValueError("Input must be a 2D (grayscale) or 3D (color) image array.")
    if img_array.shape[0] != img_array.shape[1]:
        raise ValueError("Arnold's Cat Map requires a square image. Please pad first.")

    rows, cols = img_array.shape[:2]
    is_color = img_array.ndim == 3

    # Create index grid
    x, y = np.meshgrid(np.arange(rows), np.arange(cols), indexing='ij')
    # Flatten indices for transformation
    coords = np.stack([x.flatten(), y.flatten()], axis=1)

    # Apply ACM transformation iteratively
    for i in range(iterations):
        new_coords = np.zeros_like(coords)
        # ACM formula: x' = (x + b*y) mod N, y' = (a*x + (a*b+1)*y) mod N
        new_coords[:, 0] = (coords[:, 0] + b * coords[:, 1]) % rows
        new_coords[:, 1] = (a * coords[:, 0] + (a * b + 1) * coords[:, 1]) % cols
        coords = new_coords # Update coordinates for next iteration
        # Optional: Add progress printout for large images/iterations
        # if (i+1) % 5 == 0: print(f"  ACM Iteration {i+1}/{iterations}")


    # Create the shuffled image
    shuffled_img = np.zeros_like(img_array)
    orig_indices = (x.flatten(), y.flatten()) # Original flat indices
    new_indices = (coords[:, 0], coords[:, 1]) # New flat indices after shuffling

    # Map original pixel values to new shuffled locations
    if is_color:
        for c in range(img_array.shape[2]):
            shuffled_img[new_indices[0], new_indices[1], c] = img_array[orig_indices[0], orig_indices[1], c]
    else: # Grayscale
        shuffled_img[new_indices[0], new_indices[1]] = img_array[orig_indices[0], orig_indices[1]]

    # Reshape back to original image dimensions
    return shuffled_img.reshape(img_array.shape)

def inverse_arnold_cat_map(shuffled_img_array, iterations, a=1, b=1):
    """Applies the inverse of Arnold's Cat Map."""
    if shuffled_img_array.ndim not in [2, 3]:
        raise ValueError("Input must be a 2D (grayscale) or 3D (color) image array.")
    if shuffled_img_array.shape[0] != shuffled_img_array.shape[1]:
        raise ValueError("Inverse Arnold's Cat Map requires a square image.")

    rows, cols = shuffled_img_array.shape[:2]
    is_color = shuffled_img_array.ndim == 3

    # Create index grid for the *shuffled* image
    x_shuffled, y_shuffled = np.meshgrid(np.arange(rows), np.arange(cols), indexing='ij')
    coords_shuffled = np.stack([x_shuffled.flatten(), y_shuffled.flatten()], axis=1)

    # Apply inverse ACM transformation iteratively
    # Precompute matrix elements to avoid redundant calculations inside loop? Not necessary here.
    inv_coeff_00 = a * b + 1
    inv_coeff_01 = -b
    inv_coeff_10 = -a
    inv_coeff_11 = 1

    for i in range(iterations):
        coords_orig = np.zeros_like(coords_shuffled)
        # Inverse ACM formula: x = ((a*b+1)*x' - b*y') mod N, y = (-a*x' + y') mod N
        coords_orig[:, 0] = (inv_coeff_00 * coords_shuffled[:, 0] + inv_coeff_01 * coords_shuffled[:, 1]) % rows
        coords_orig[:, 1] = (inv_coeff_10 * coords_shuffled[:, 0] + inv_coeff_11 * coords_shuffled[:, 1]) % cols
        coords_shuffled = coords_orig # Update coordinates for next iteration
        # Optional: Add progress printout
        # if (i+1) % 5 == 0: print(f"  Inv ACM Iteration {i+1}/{iterations}")


    # Create the unshuffled image
    unshuffled_img = np.zeros_like(shuffled_img_array)
    shuffled_indices = (x_shuffled.flatten(), y_shuffled.flatten()) # Indices in the input shuffled image
    original_indices = (coords_shuffled[:, 0], coords_shuffled[:, 1]) # Calculated original indices

    # Map shuffled pixel values back to their original locations
    if is_color:
        for c in range(shuffled_img_array.shape[2]):
            unshuffled_img[original_indices[0], original_indices[1], c] = shuffled_img_array[shuffled_indices[0], shuffled_indices[1], c]
    else: # Grayscale
        unshuffled_img[original_indices[0], original_indices[1]] = shuffled_img_array[shuffled_indices[0], shuffled_indices[1]]

    return unshuffled_img.reshape(shuffled_img_array.shape)

# --- Logistic Map Chaos Encryption ---
def generate_logistic_map_sequence(x0, r, size):
    """Generates a chaotic sequence using the Logistic Map."""
    # Ensure parameters are floats
    x0 = float(x0)
    r = float(r)
    sequence = np.zeros(size, dtype=np.float64) # Use float64 for better precision
    x = x0
    # Burn-in iterations to reach chaotic regime
    # print("Logistic Map: Burn-in...") # Optional print
    for _ in range(100): # Discard initial values
        x = r * x * (1.0 - x)
    # Generate the sequence
    # print("Logistic Map: Generating sequence...") # Optional print
    for i in range(size):
        x = r * x * (1.0 - x)
        sequence[i] = x
        # Handle potential precision issues leading to exact 0 or 1 (unlikely with float64 but safe)
        if x == 0.0 or x == 1.0:
            # print(f"Warning: Logistic map sequence hit {x} at iteration {i}. Re-seeding slightly.")
            # Adding a tiny value might push it out of fixed point, but could introduce bias
            # x = np.fmod(x + 1e-9, 1.0) # Add small perturbation and wrap around using fmod
            # A potentially safer approach is to slightly perturb r or x0 if this happens often
            # For now, just continue, it's rare with proper parameters
            pass

    return sequence

def logistic_map_encrypt_decrypt(img_array, x0, r):
    """Encrypts or decrypts using Logistic Map sequence via XOR."""
    if img_array.ndim not in [2, 3]:
        raise ValueError("Input must be a 2D (grayscale) or 3D (color) image array.")
    img_dtype = img_array.dtype
    if img_dtype != np.uint8:
        print(f"Warning: Input image array dtype is {img_dtype}. Converting to uint8 for XOR.")
        img_array = img_array.astype(np.uint8)

    is_color = img_array.ndim == 3
    total_pixels = img_array.size # Total number of elements (pixels * channels)

    # Parameter checks for logistic map
    if not (3.57 <= r <= 4.0):
        print(f"Warning: Logistic map parameter r={r} might not be in the typical chaotic range [3.57, 4.0]. Results may be insecure.")
    if not (0 < x0 < 1):
         print(f"Warning: Logistic map initial value x0={x0} should be between 0 and 1. Clipping to avoid issues.")
         # Clip x0 slightly away from 0 and 1
         x0 = np.clip(x0, 1e-6, 1.0 - 1e-6)

    try:
        # Generate keystream (float values between 0 and 1)
        keystream_float = generate_logistic_map_sequence(x0, r, total_pixels)
        # Scale to 0-255 and convert to uint8 for XOR
        # Scaling by 255.999... maps (0, 1) to [0, 255] after casting
        keystream_uint8 = (keystream_float * 255.999999).astype(np.uint8)
    except OverflowError:
        print(f"FATAL: OverflowError during logistic map generation with r={r}, x0={x0}. This usually indicates unstable parameters. Stopping.")
        # Using fallback random stream here masks instability, better to raise error
        raise ValueError(f"Logistic map overflowed with r={r}, x0={x0}.")
        # keystream_uint8 = np.random.randint(0, 256, size=total_pixels, dtype=np.uint8)

    # Flatten image and keystream for XOR operation
    # Ensure keystream matches the flattened image length precisely
    keystream_reshaped = keystream_uint8 # Already flat
    img_flat = img_array.flatten()

    if len(img_flat) != len(keystream_reshaped):
         raise ValueError(f"Image flat size ({len(img_flat)}) and keystream size ({len(keystream_reshaped)}) mismatch.")

    # Perform XOR operation element-wise
    processed_flat = np.bitwise_xor(img_flat, keystream_reshaped)

    # Reshape back to original image shape
    processed_img = processed_flat.reshape(img_array.shape)
    # Ensure output is uint8
    return processed_img.astype(np.uint8)

# --- Combined Encryption Function ---
def encrypt_image(img_array, acm_iterations, logistic_x0, logistic_r, acm_a=1, acm_b=1):
    """Combines ACM shuffling and Logistic Map encryption on pixel data."""
    print("Starting Encryption Process...")
    start_time = time.time()
    # 1. Shuffle pixels with Arnold's Cat Map
    print(f"Applying Arnold's Cat Map with {acm_iterations} iterations (a={acm_a}, b={acm_b})...")
    try:
        # Ensure input is uint8 before shuffling if needed (though ACM itself doesn't require it)
        if img_array.dtype != np.uint8:
            print(f"  Converting image to uint8 before ACM.")
            img_array = img_array.astype(np.uint8)
        shuffled_img = arnold_cat_map(img_array, acm_iterations, acm_a, acm_b)
    except ValueError as e:
        print(f"Error during ACM: {e}. Returning original image.")
        return img_array, 0 # Return original and 0 time

    # 2. Encrypt pixel values with Logistic Map XOR
    print(f"Applying Logistic Map encryption (x0={logistic_x0}, r={logistic_r})...")
    try:
        encrypted_img = logistic_map_encrypt_decrypt(shuffled_img, logistic_x0, logistic_r)
    except ValueError as e:
        print(f"Error during Logistic Map encryption: {e}. Returning shuffled image.")
        return shuffled_img, time.time() - start_time # Return intermediate and partial time

    end_time = time.time()
    encryption_time = end_time - start_time
    print(f"Encryption completed in {encryption_time:.4f} seconds.")
    return encrypted_img, encryption_time


# %% [markdown]
# ## Task 3: Compression (zlib) and Hashing of Compressed Data

# %%
def compress_data(data_array):
    """Compresses a NumPy array using zlib."""
    print("Starting Compression...")
    start_time = time.time()
    # Ensure data is in bytes format
    try:
        original_bytes = data_array.tobytes()
    except AttributeError:
         print("Error: Input data_array does not support .tobytes(). Is it a NumPy array?")
         return None, 0

    # Use a good compression level (1-9, 9 is highest, 6 is default)
    compression_level = 7 # Good balance
    compressed_bytes = zlib.compress(original_bytes, level=compression_level)
    end_time = time.time()
    compression_time = end_time - start_time

    original_size = len(original_bytes)
    compressed_size = len(compressed_bytes)
    ratio = compressed_size / original_size if original_size > 0 else 0
    print(f"Compression (zlib level {compression_level}) completed in {compression_time:.4f} seconds.")
    print(f"Original size: {original_size} bytes, Compressed size: {compressed_size} bytes, Ratio: {ratio:.4f}")
    return compressed_bytes, compression_time

def calculate_hash_bytes(byte_data):
    """Calculates the SHA-256 hash of byte data."""
    if not isinstance(byte_data, bytes):
        raise TypeError("Input for hashing must be bytes.")
    hasher = hashlib.sha256()
    hasher.update(byte_data)
    return hasher.hexdigest()
def steghide_embed_metadata(image_data, metadata_dict):
    """Embeds metadata into the least significant bits of an image."""
    print("\n--- Performing Steganography: Hiding Metadata ---")
    
    # Convert image to numpy array if it isn't already
    if not isinstance(image_data, np.ndarray):
        print("Error: Image data must be a NumPy array for steganography")
        return image_data, False
        
    # Make a copy to avoid modifying the original
    steg_img = image_data.copy()
    
    # Convert metadata to JSON and then to bytes
    try:
        import json
        metadata_json = json.dumps(metadata_dict)
        metadata_bytes = metadata_json.encode('utf-8')
        
        # Add length prefix for extraction (4 bytes = 32 bits for length)
        length_bytes = len(metadata_bytes).to_bytes(4, byteorder='big')
        full_payload = length_bytes + metadata_bytes
        
        print(f"Metadata size: {len(metadata_bytes)} bytes")
        print(f"Total payload with header: {len(full_payload)} bytes")
        
        # Check if image has enough capacity (each pixel can store 1 bit, we need 8 * len(full_payload) bits)
        required_pixels = 8 * len(full_payload)
        available_pixels = steg_img.size
        
        if required_pixels > available_pixels:
            print(f"Error: Image too small for metadata ({required_pixels} bits needed, {available_pixels} available)")
            return image_data, False
            
        # Flatten the image for easier bit manipulation
        flat_img = steg_img.flatten()
        
        # Convert payload bytes to bits
        payload_bits = []
        for byte in full_payload:
            for bit in range(8):
                payload_bits.append((byte >> bit) & 1)
                
        # Embed bits into LSB of pixels
        for i, bit in enumerate(payload_bits):
            if i >= len(flat_img):
                break
            # Clear the LSB and set it to our bit
            flat_img[i] = (flat_img[i] & 0xFE) | bit
            
        # Reshape back to original dimensions
        steg_img = flat_img.reshape(image_data.shape)
        
        print(f"Successfully embedded {len(payload_bits)} bits of metadata")
        return steg_img, True
        
    except Exception as e:
        print(f"Steganography embedding failed: {e}")
        traceback.print_exc()
        return image_data, False

def steghide_extract_metadata(steg_img):
    """Extracts metadata hidden in the least significant bits of an image."""
    print("\n--- Extracting Hidden Metadata from Steganography ---")
    
    if not isinstance(steg_img, np.ndarray):
        print("Error: Image data must be a NumPy array for extraction")
        return None
        
    try:
        # Flatten the image
        flat_img = steg_img.flatten()
        
        # Extract the length header first (first 32 bits = 4 bytes)
        length_bits = [flat_img[i] & 1 for i in range(32)]
        
        # Convert bits to bytes
        length_bytes = bytearray()
        for i in range(0, 32, 8):
            byte = 0
            for bit in range(8):
                if i+bit < len(length_bits):
                    byte |= (length_bits[i+bit] << bit)
            length_bytes.append(byte)
            
        # Convert bytes to integer
        metadata_length = int.from_bytes(length_bytes, byteorder='big')
        print(f"Detected metadata length: {metadata_length} bytes")
        
        if metadata_length <= 0 or metadata_length > 1000000:  # Sanity check
            print("Invalid metadata length detected, possible extraction error")
            return None
            
        # Extract the metadata bits (after the 32-bit length header)
        metadata_bits = [flat_img[i] & 1 for i in range(32, 32 + 8*metadata_length)]
        
        # Convert bits to bytes
        metadata_bytes = bytearray()
        for i in range(0, len(metadata_bits), 8):
            byte = 0
            for bit in range(8):
                if i+bit < len(metadata_bits):
                    byte |= (metadata_bits[i+bit] << bit)
            metadata_bytes.append(byte)
            
        # Decode bytes to JSON
        import json
        metadata_json = metadata_bytes.decode('utf-8')
        metadata_dict = json.loads(metadata_json)
        
        print(f"Successfully extracted metadata: {len(metadata_dict)} fields")
        return metadata_dict
        
    except Exception as e:
        print(f"Metadata extraction failed: {e}")
        traceback.print_exc()
        return None

# %% [markdown]
# ## Task 4: Decompression (zlib), Decryption & Integrity Verification

# %%
def decompress_data(compressed_bytes, original_shape, original_dtype):
    """Decompresses byte data (from zlib) back into a NumPy array."""
    print("Starting Decompression...")
    start_time = time.time()
    if not isinstance(compressed_bytes, bytes):
         print("Error: Input for decompression must be bytes.")
         return None, 0

    try:
        decompressed_bytes = zlib.decompress(compressed_bytes)

        # --- Verification Step ---
        # Calculate expected size in bytes from shape and dtype
        try:
             dtype_itemsize = np.dtype(original_dtype).itemsize
             expected_bytes = np.prod(original_shape) * dtype_itemsize
        except TypeError as e:
             print(f"Error calculating expected size: Invalid shape {original_shape} or dtype {original_dtype}? {e}")
             # Cannot reliably reshape if expected size is unknown
             raise ValueError("Cannot determine expected size from shape/dtype.")


        if len(decompressed_bytes) != expected_bytes:
             print(f"FATAL: Decompressed byte count ({len(decompressed_bytes)}) does not match expected count ({expected_bytes}) based on provided shape {original_shape} and dtype {original_dtype}.")
             print("This indicates data corruption, incorrect shape/dtype passed, or compression issues.")
             # Return None as reshaping will fail or produce incorrect data
             return None, time.time() - start_time # Return None and time taken so far

        # --- Reshape Step ---
        # Convert bytes back to NumPy array using the known dtype
        data_array = np.frombuffer(decompressed_bytes, dtype=original_dtype)
        # Reshape to the original array dimensions
        data_array = data_array.reshape(original_shape)

        end_time = time.time()
        decompression_time = end_time - start_time
        print(f"Decompression completed in {decompression_time:.4f} seconds.")
        return data_array, decompression_time

    except zlib.error as e:
        print(f"Error during zlib decompression: {e}. Data may be corrupted.")
        return None, time.time() - start_time
    except ValueError as e:
        # This might catch the reshape error if the byte count check above was bypassed
        print(f"Error reshaping decompressed data (likely size mismatch or shape/dtype error): {e}")
        return None, time.time() - start_time
    except Exception as e:
        print(f"An unexpected error occurred during decompression: {e}")
        traceback.print_exc() # Print full traceback for unexpected errors
        return None, time.time() - start_time


def decrypt_image(encrypted_img_array, acm_iterations, logistic_x0, logistic_r, original_shape_before_padding, padded, acm_a=1, acm_b=1):
    """Reverses the encryption: Logistic Map decrypt -> Inverse ACM -> Unpad."""
    # Input `encrypted_img_array` here is the *decompressed* encrypted image.
    if encrypted_img_array is None:
         print("Error: Cannot decrypt None input.")
         return None, 0

    print("Starting Decryption Process (on decompressed data)...")
    start_time = time.time()

    # 1. Decrypt pixel values using Logistic Map (XOR is its own inverse)
    print(f"Applying Logistic Map decryption (x0={logistic_x0}, r={logistic_r})...")
    try:
        decrypted_shuffled_img = logistic_map_encrypt_decrypt(encrypted_img_array, logistic_x0, logistic_r)
    except ValueError as e:
         print(f"Error during Logistic Map decryption: {e}. Returning None.")
         return None, time.time() - start_time

    # 2. Unshuffle pixels using Inverse Arnold's Cat Map
    print(f"Applying Inverse Arnold's Cat Map with {acm_iterations} iterations (a={acm_a}, b={acm_b})...")
    try:
        unshuffled_padded_img = inverse_arnold_cat_map(decrypted_shuffled_img, acm_iterations, acm_a, acm_b)
    except ValueError as e:
         print(f"Error during Inverse ACM: {e}. Cannot unpad. Returning partially decrypted (shuffled) image.")
         # We can't reliably unpad if the inverse shuffling failed
         return decrypted_shuffled_img, time.time() - start_time

    # 3. Remove padding if it was added during preprocessing
    final_decrypted_img = unshuffled_padded_img # Assume no padding needed initially
    if padded: # Check the flag passed from preprocessing
        current_h, current_w = unshuffled_padded_img.shape[:2]
        orig_h, orig_w = original_shape_before_padding # Use the original size before padding

        # Basic sanity check on dimensions before slicing
        if orig_h > current_h or orig_w > current_w:
             print(f"Error: Original dimensions ({orig_h}x{orig_w}) seem larger than current image dimensions ({current_h}x{current_w}) after inverse ACM. Cannot unpad.")
             # Return the unshuffled padded image as best result possible
             return unshuffled_padded_img, time.time() - start_time

        # Sanity check: Did padding actually change dimensions?
        if current_h != orig_h or current_w != orig_w:
            print(f"Removing padding to restore original size {original_shape_before_padding}...")
            # Calculate how much padding was added (total)
            pad_h_total = current_h - orig_h
            pad_w_total = current_w - orig_w
            # Calculate padding on each side (assuming symmetric padding was used)
            pad_top = pad_h_total // 2
            pad_left = pad_w_total // 2

            # Slice the array to remove padding
            try:
                if unshuffled_padded_img.ndim == 3: # Color
                    final_decrypted_img = unshuffled_padded_img[pad_top : pad_top + orig_h, pad_left : pad_left + orig_w, :]
                else: # Grayscale
                    final_decrypted_img = unshuffled_padded_img[pad_top : pad_top + orig_h, pad_left : pad_left + orig_w]
                print(f"Final decrypted size after unpadding: {final_decrypted_img.shape[:2]}")
            except IndexError as e:
                 print(f"Error during unpadding slice (calculated indices might be wrong): {e}")
                 print(f"  current={current_h}x{current_w}, orig={orig_h}x{orig_w}, top={pad_top}, left={pad_left}")
                 # Return the unshuffled padded image as best result possible
                 return unshuffled_padded_img, time.time() - start_time
        else:
            # This case implies padding flag was true, but dimensions didn't change. Maybe original was already square?
             print("Padding flag was set, but dimensions seem to match the original size. No padding removed.")
             final_decrypted_img = unshuffled_padded_img # Keep the image as is
    else:
        print("No padding was added initially, skipping unpadding step.")

    end_time = time.time()
    decryption_time = end_time - start_time
    print(f"Decryption completed in {decryption_time:.4f} seconds.")
    # Ensure output is uint8, especially important after potential float operations in analysis tools later
    return final_decrypted_img.astype(np.uint8), decryption_time

def verify_integrity_compressed(received_compressed_data, original_compressed_hash):
    """Compares the hash of the received compressed data with the original expected hash."""
    print(f"\n--- Tamper Verification (Compressed Data) ---")
    if not isinstance(received_compressed_data, bytes):
        print("Error: Received data for hash verification is not bytes.")
        return False
    if not isinstance(original_compressed_hash, str) or len(original_compressed_hash) != 64:
        print("Error: Original hash for comparison is invalid.")
        return False

    print(f"Expected Hash:  {original_compressed_hash}")
    # Calculate hash of the received compressed data
    try:
        calculated_hash = calculate_hash_bytes(received_compressed_data)
        print(f"Calculated Hash:{calculated_hash}")
    except Exception as e:
        print(f"Error calculating hash of received data: {e}")
        return False

    if original_compressed_hash == calculated_hash:
        print("Integrity Check PASSED: Compressed data hashes match.")
        return True
    else:
        print("Integrity Check FAILED: Compressed data hashes DO NOT match. Data may be corrupted or tampered with.")
        return False


# %% [markdown]
# ## Task 5: Performance Analysis (Functions - Mostly Unchanged)

# %%
def calculate_metrics(img_orig, img_processed, data_range=255):
    """Calculates MSE, PSNR, SSIM, and Entropy."""
    # Ensure inputs are NumPy arrays
    if not isinstance(img_orig, np.ndarray) or not isinstance(img_processed, np.ndarray):
        print("Error: Inputs for metrics must be NumPy arrays.")
        # Return default/error values
        entropy_orig = shannon_entropy(img_orig) if isinstance(img_orig, np.ndarray) else float('nan')
        return {'mse': float('inf'), 'psnr': 0, 'ssim': 0, 'entropy_orig': entropy_orig, 'entropy_proc': float('nan')}

    # Ensure images are uint8 for standard metrics
    # Check dtype *before* astype to avoid unnecessary conversions/warnings
    if img_orig.dtype != np.uint8:
         # print(f"Converting original image from {img_orig.dtype} to uint8 for metrics.")
         img_orig = img_orig.astype(np.uint8)
    if img_processed.dtype != np.uint8:
         # print(f"Converting processed image from {img_processed.dtype} to uint8 for metrics.")
         img_processed = img_processed.astype(np.uint8)


    if img_orig.shape != img_processed.shape:
        print(f"Warning: Original ({img_orig.shape}) and processed ({img_processed.shape}) images have different shapes for metrics calculation.")
        print("This often happens if decryption/unpadding failed.")
        print("Metrics calculation skipped due to shape mismatch.")
        return {'mse': float('inf'), 'psnr': 0, 'ssim': 0, 'entropy_orig': shannon_entropy(img_orig), 'entropy_proc': float('nan')}

    # --- Calculate Metrics ---
    try:
        mse_val = mse(img_orig, img_processed)
    except Exception as e:
        print(f"Error calculating MSE: {e}")
        mse_val = float('inf')

    try:
        # PSNR calculation handles mse_val=0 correctly (returns inf)
        psnr_val = psnr(img_orig, img_processed, data_range=data_range)
    except Exception as e:
        print(f"Error calculating PSNR: {e}")
        psnr_val = 0 # Or float('-inf')? 0 is common for error.

    # SSIM calculation
    ssim_val = 0 # Default in case of error or small image
    try:
        multichannel = img_orig.ndim == 3
        min_dim = min(img_orig.shape[:2])
        # Default SSIM window size in skimage is min(7, N) where N is spatial dimension
        # Ensure window size is odd and >= 3
        win_size = min(7, min_dim)
        if win_size < 3:
             print(f"Image dimensions ({img_orig.shape[:2]}) too small for SSIM. Setting SSIM to 0.")
        elif win_size % 2 == 0:
             win_size -= 1 # Make odd

        if win_size >= 3:
             # Determine channel_axis based on multichannel flag AFTER checking dimensions
             c_axis = 2 if multichannel else None
             ssim_val = ssim(img_orig, img_processed, data_range=data_range,
                             multichannel=multichannel, channel_axis=c_axis,
                             win_size=win_size)
    except ValueError as e:
         # Catch potential errors like window size > image dimension
         print(f"Error calculating SSIM (check window size vs image dim): {e}. Setting SSIM to 0.")
         ssim_val = 0
    except Exception as e:
         print(f"Unexpected error calculating SSIM: {e}")
         ssim_val = 0


    # Entropy calculation
    try:
        entropy_orig_val = shannon_entropy(img_orig)
    except Exception as e:
        print(f"Error calculating original entropy: {e}")
        entropy_orig_val = float('nan')
    try:
        entropy_proc_val = shannon_entropy(img_processed)
    except Exception as e:
        print(f"Error calculating processed entropy: {e}")
        entropy_proc_val = float('nan')


    metrics = {
        'mse': mse_val,
        'psnr': psnr_val,
        'ssim': ssim_val,
        'entropy_orig': entropy_orig_val,
        'entropy_proc': entropy_proc_val
    }
    return metrics

def plot_histograms(img_orig, img_encrypted, img_decrypted):
    """Plots histograms for original, encrypted (padded), and decrypted images."""
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))
    fig.suptitle('Image Histograms', fontsize=16)
    colors = ('r', 'g', 'b')
    labels = ('Original (Unpadded)', 'Encrypted (Padded)', 'Decrypted (Final)')
    images = (img_orig, img_encrypted, img_decrypted)

    for i, img in enumerate(images):
        ax = axes[i]
        if img is None or not isinstance(img, np.ndarray): # Check if image data is valid
            ax.set_title(f"{labels[i]} (Not Available)")
            ax.text(0.5, 0.5, 'N/A', ha='center', va='center', transform=ax.transAxes, fontsize=12, color='red')
            ax.set_xticks([])
            ax.set_yticks([])
            continue

        # Proceed with plotting if image is valid
        ax.set_title(labels[i] + f" {img.shape}") # Add shape to title
        ax.set_xlabel('Pixel Intensity'); ax.set_ylabel('Frequency')
        try:
            if img.ndim == 3: # Color image
                # Plot histogram for each color channel
                for c_idx, color in enumerate(colors):
                    if c_idx < img.shape[2]: # Check if channel exists (e.g., might be 2-channel?)
                        # Use np.histogram for robustness
                        hist, bin_edges = np.histogram(img[:, :, c_idx].ravel(), bins=256, range=[0, 256])
                        ax.plot(bin_edges[:-1], hist, color=color, alpha=0.7, label=f'Ch {color.upper()}')
                if img.shape[2] > 1 : ax.legend(loc='upper right') # Show legend only if multiple channels plotted
            elif img.ndim == 2: # Grayscale image
                hist, bin_edges = np.histogram(img.ravel(), bins=256, range=[0, 256])
                ax.plot(bin_edges[:-1], hist, color='black')
            else:
                 ax.text(0.5, 0.5, f'Invalid Dim {img.ndim}', ha='center', va='center', transform=ax.transAxes)


            ax.set_xlim([0, 255])
            ax.grid(True, linestyle='--', alpha=0.6)
        except Exception as e:
             print(f"Error plotting histogram for {labels[i]}: {e}")
             ax.text(0.5, 0.5, 'Plotting Error', ha='center', va='center', transform=ax.transAxes, color='red')


    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent title overlap
    plt.show()

def display_images(img_orig, img_encrypted, img_decrypted):
    """Displays the original (unpadded), encrypted (padded), and decrypted (final) images."""
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    fig.suptitle('Image Encryption Results', fontsize=16)
    titles = ['Original Image (Unpadded)', 'Encrypted Image (Padded)', 'Decrypted Image (Final)']
    images = [img_orig, img_encrypted, img_decrypted]

    for ax, img, title in zip(axes, images, titles):
        ax.set_title(title)
        ax.axis('off') # Hide axes ticks
        if img is not None and isinstance(img, np.ndarray):
            # Determine colormap (grayscale or color)
            cmap = 'gray' if img.ndim == 2 else None
            try:
                ax.imshow(img, cmap=cmap)
            except Exception as e:
                 print(f"Error displaying image '{title}': {e}")
                 ax.text(0.5, 0.5, 'Display Error', ha='center', va='center', transform=ax.transAxes, color='red')

        else:
             # Display N/A if image is missing or invalid
             ax.text(0.5, 0.5, 'N/A', ha='center', va='center', transform=ax.transAxes, fontsize=12, color='red')

    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout
    plt.show()

# --- Helper for Jupyter Download Link ---
def create_download_link_jupyter(filename, data_bytes, link_text, mime_type='application/octet-stream'):
    """Generates an HTML download link for Jupyter using base64 encoded bytes."""
    if ENV != 'jupyter' or not isinstance(data_bytes, bytes):
        return "" # Only run in Jupyter env and only if data is bytes
    try:
        b64 = base64.b64encode(data_bytes).decode('ascii') # Use ascii for base64
        href = f'<a href="data:{mime_type};base64,{b64}" download="{os.path.basename(filename)}">{link_text}</a>'
        return href
    except Exception as e:
        print(f"Error creating download link for {filename}: {e}")
        return f"<span>Error creating link for {filename}</span>"


# %% [markdown]
# ## Main Execution Block (Upload, Process, Analyze, Download)

# %%
# --- Configuration ---
# Encryption Keys (!!! USE SECURE RANDOM KEYS IN PRACTICE !!!)
# Using fixed keys for reproducibility in demo
ACM_ITERATIONS = 10 # Lowered slightly for potentially large images
ACM_A = 1; ACM_B = 1 # Standard ACM parameters
LOGISTIC_X0 = 0.31415926535 # Initial condition for logistic map (use high precision)
LOGISTIC_R = 3.9999          # Parameter for logistic map (very close to 4, highly chaotic)

# Preprocessing settings
USE_GRAYSCALE = False             # Convert to grayscale before processing?
SIMULATE_LOW_BANDWIDTH = False    # Resize image to simulate low bandwidth?
RESIZE_TARGET = None #(512, 512)  # Target size if resizing (e.g., (256, 256)). None means no resize.

# Output filenames
# NOTE: Encrypted file now stores compressed raw data, suggest non-image extension
COMPRESSED_ENCRYPTED_FILENAME = "encrypted_compressed_data.zlib" # Changed extension
DECRYPTED_FILENAME = "decrypted_image.png" # Keep as PNG

# --- Global variables to store results across steps (initialize) ---
original_image_unpadded = None
original_image_padded = None
encrypted_image = None
compressed_encrypted_data = None
transmitted_hash = None
decompressed_encrypted_image = None
final_decrypted_image = None
integrity_check_passed = False # Assume failure until success
encryption_time = 0
compression_time = 0
decompression_time = 0
decryption_time = 0
original_size_before_padding = (0,0)
was_padded = False
encrypted_shape = None
encrypted_dtype = None


# --- Get Image Input ---
uploaded_file_name = None
img_data_input = None # This will hold the image data (BytesIO, path, etc.)

print("--- Starting Setup ---") # Added print

if ENV == 'colab':
    print("Environment: Google Colab")
    print("Please upload an image file:")
    try:
        uploaded = files.upload()
        if uploaded:
            # Get the first uploaded file's name and content
            uploaded_file_name = next(iter(uploaded))
            img_data_input = uploaded[uploaded_file_name] # Pass raw bytes to preprocessing
            print(f"Successfully uploaded: {uploaded_file_name} ({len(img_data_input)} bytes)")
        else:
            print("No file uploaded. Will use fallback image.")
            img_data_input = None # Let preprocessing handle fallback
    except Exception as e:
        print(f"An error occurred during Colab upload: {e}")
        img_data_input = None # Let preprocessing handle fallback

elif ENV == 'jupyter':
     print("Environment: Jupyter Notebook/Lab")
     print("Please use the widget below to upload an image file:")
     # Define the uploader widget
     uploader = widgets.FileUpload(
         accept='image/*', # Allow common image types
         multiple=False, # Allow only single file upload
         description="Upload Image" # Add description
     )
     display(uploader) # Show the widget
     # IMPORTANT FOR JUPYTER:
     # 1. Run this cell.
     # 2. Use the widget that appears above to upload your file.
     # 3. Manually run the NEXT cell (Processing & Analysis) after upload completes.
     # We store the uploader object ('uploader') to retrieve the value in the next cell.

     # Optional: Provide a hardcoded path as a fallback if widget isn't used
     # file_path = "lena_color.png" # Example path
     # if 'uploader' not in locals() or not uploader.value: # Check if widget was used
     #      if os.path.exists(file_path):
     #           img_data_input = file_path
     #           uploaded_file_name = os.path.basename(file_path)
     #           print(f"Using hardcoded file path: {file_path}")
     #      else:
     #           print(f"Hardcoded file path not found: {file_path}. Please use upload widget or provide valid path.")
     #           img_data_input = None # Ensure it's None if file not found

else: # 'other' environment (e.g., standard Python script)
    print("Environment: Other (e.g., script)")
    # Fallback: Specify a local file path directly
    # !!! USER ACTION REQUIRED: Change this path to your image file !!!
    try:
        # Default path, user should change this
        file_path = "input_image.png" # <--- CHANGE THIS PATH IF NEEDED
        # Check if file exists before proceeding
        if os.path.exists(file_path):
            img_data_input = file_path # Pass the path string to preprocessing
            uploaded_file_name = os.path.basename(file_path)
            print(f"Using local file: {file_path}")
        else:
             print(f"File not found at specified path: {file_path}.")
             print("Will use fallback image.")
             img_data_input = None # Let preprocessing handle fallback
    except Exception as e:
        print(f"Error accessing local file path '{file_path}': {e}")
        img_data_input = None # Let preprocessing handle fallback


# %% [markdown]
# ## Processing & Analysis (Run this cell after upload completes)

# %%
# --- Continue Execution (Run this cell after uploading in Jupyter) ---

# Handle Jupyter upload widget result if applicable
if ENV == 'jupyter' and 'uploader' in locals() and uploader.value:
    try:
        # uploader.value is a dictionary where keys are filenames and values are file info dicts
        uploaded_file_key = list(uploader.value.keys())[0] # Get the first filename key
        uploaded_file_info = uploader.value[uploaded_file_key] # Get the file info dict

        uploaded_file_name = uploaded_file_info['metadata']['name']
        # Pass the raw content (bytes) directly to preprocessing
        img_data_input = uploaded_file_info['content']
        print(f"Processing uploaded file (Jupyter): {uploaded_file_name} ({len(img_data_input)} bytes)")
        # Optional: Clear the widget value if you want to allow re-runs with new uploads easily
        # uploader.value.clear()
        # uploader._counter = 0 # Reset counter to allow re-upload of same file name
    except Exception as e:
        print(f"Error processing Jupyter upload: {e}")
        # Ensure img_data_input is None if processing fails, allowing fallback
        img_data_input = None


# --- Main Processing Pipeline ---
# Wrap the entire pipeline in a try/except/finally block for robust error handling

print("\n--- Starting Image Processing Pipeline ---")
# Make sure traceback is imported if an error occurs
# import traceback # Already imported earlier

# <<<< ****** START OF THE MAIN TRY BLOCK ****** >>>>
try:
    # --- Step 1: Preprocessing ---
    print("\n--- Task 1: Preprocessing ---")
    # Returns the potentially padded square array, the original size (h, w) before padding, and a flag
    original_image_padded, original_size_before_padding, was_padded = preprocess_image(
        img_data_input, # Can be BytesIO, path string, bytes, or None
        target_size=RESIZE_TARGET,
        grayscale=USE_GRAYSCALE,
        simulate_low_bandwidth=SIMULATE_LOW_BANDWIDTH
    )

    if original_image_padded is None:
        raise ValueError("Preprocessing failed to produce an image array.")

    # Store the original unpadded image for final comparison/metrics
    # Reconstruct it *before* encryption affects the padded version
    h_orig, w_orig = original_size_before_padding
    if was_padded:
        # Calculate padding amounts used during preprocess_image
        pad_h_total = original_image_padded.shape[0] - h_orig
        pad_w_total = original_image_padded.shape[1] - w_orig
        pad_top = pad_h_total // 2
        pad_left = pad_w_total // 2
        # Slice carefully
        if original_image_padded.ndim == 3:
            original_image_unpadded = original_image_padded[pad_top : pad_top + h_orig, pad_left : pad_left + w_orig, :].copy()
        else: # Grayscale
            original_image_unpadded = original_image_padded[pad_top : pad_top + h_orig, pad_left : pad_left + w_orig].copy()
    else:
        # If not padded, the 'padded' array is the original (or resized) one
        original_image_unpadded = original_image_padded.copy()

    print(f"Original image dimensions stored for metrics: {original_image_unpadded.shape}")
    print(f"Image array type after preprocessing: {original_image_padded.dtype}")


    # --- Step 2: Encryption ---
    print("\n--- Task 2: Encryption ---")
    # Encrypt the potentially padded image array
    encrypted_image, encryption_time = encrypt_image(
        original_image_padded, # Use the square, padded array for ACM
        acm_iterations=ACM_ITERATIONS,
        logistic_x0=LOGISTIC_X0, logistic_r=LOGISTIC_R,
        acm_a=ACM_A, acm_b=ACM_B
    )
    if encrypted_image is None:
        raise ValueError("Encryption failed.")
    # Store shape and dtype needed for decompression later
    encrypted_shape = encrypted_image.shape
    encrypted_dtype = encrypted_image.dtype
    print(f"Encrypted image shape: {encrypted_shape}, dtype: {encrypted_dtype}")
    # --- Step 2.5: Steganography - Embedding Metadata ---
    print("\n--- Task 2.5: Steganography - Embedding Metadata ---")
    # Create metadata dictionary with encryption parameters and other information
    metadata = {
        "encrypted_by": "Your Name",
        "description": "Secure image encryption with steganography",
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "encryption_params": {
            "acm_iterations": ACM_ITERATIONS,
            "acm_a": ACM_A,
            "acm_b": ACM_B,
            "original_shape": original_image_unpadded.shape if original_image_unpadded is not None else None
        }
    }

    # Apply steganography directly to the encrypted image data
    try:
        encrypted_image_with_steg, steg_success = steghide_embed_metadata(encrypted_image, metadata)
        
        if steg_success:
            encrypted_image = encrypted_image_with_steg  # Replace encrypted image with steg version
            print("✅ Successfully embedded metadata using steganography")
        else:
            print("⚠️ Steganography embedding failed, using original encrypted data")
    except Exception as e:
        print(f"Steganography process failed: {e}")
        # Continue with original encrypted data

    # --- Step 3: Compression ---
    print("\n--- Task 3: Compression (zlib) ---")
    # Compress the encrypted image array
    compressed_encrypted_data, compression_time = compress_data(encrypted_image)
    if compressed_encrypted_data is None:
        raise ValueError("Compression failed.")


    # --- Step 4: Hashing (for Tamper Proofing) ---
    print("\n--- Task 4: Hashing Compressed Data ---")
    # Calculate hash of the compressed data (this is what we'd "transmit")
    transmitted_hash = calculate_hash_bytes(compressed_encrypted_data)
    print(f"Calculated SHA-256 Hash of Compressed Data: {transmitted_hash}")


    # --- (Simulate Reception & Tamper Check) ---
    # In a real scenario, 'received_compressed_data' would come from network/disk
    # For this single-cell demo, we just use the variable we have.
    received_compressed_data = compressed_encrypted_data
    received_hash = transmitted_hash # Assume the hash is received correctly alongside

    # Verify integrity of the compressed data *before* decompression
    integrity_check_passed = verify_integrity_compressed(received_compressed_data, received_hash)


    # --- Step 5: Decompression (if integrity check passed) ---
    # --- Step 5: Decompression (if integrity check passed) ---
    if integrity_check_passed:
        print("\n--- Task 5: Decompression (zlib) ---")
        # Decompress the data, needs the original shape and dtype of the *encrypted* array
        decompressed_encrypted_image, decompression_time = decompress_data(
            received_compressed_data,
            encrypted_shape,
            encrypted_dtype
        )
        if decompressed_encrypted_image is None:
            print("Decompression failed. Cannot proceed with decryption.")
            # Mark overall process as failed if decompression fails
            integrity_check_passed = False
        else:
            # --- Extract metadata from steganography now that we have decompressed data ---
            print("\n--- Extracting Metadata from Steganography ---")
            try:
                extracted_metadata = steghide_extract_metadata(decompressed_encrypted_image)
                
                if extracted_metadata:
                    print("\n--- Steganography Metadata Retrieved ---")
                    for key, value in extracted_metadata.items():
                        print(f"{key}: {value}")
                    print("\n")
            except Exception as e:
                print(f"Metadata extraction failed: {e}")
                # Continue with normal decryption flow
    else:
        print("\nSkipping Decompression and Decryption due to failed integrity check.")
        decompressed_encrypted_image = None

    # --- Step 6: Decryption (if decompression was successful) ---
    # Also check integrity_check_passed again, in case decompression failed
    if integrity_check_passed and decompressed_encrypted_image is not None:
        print("\n--- Task 6: Decryption ---")
        # Decrypt the decompressed image array
        # Pass original size and padding flag for correct unpadding
        final_decrypted_image, decryption_time = decrypt_image(
            decompressed_encrypted_image,
            acm_iterations=ACM_ITERATIONS,
            logistic_x0=LOGISTIC_X0, logistic_r=LOGISTIC_R,
            original_shape_before_padding=original_size_before_padding, # Original H, W tuple
            padded=was_padded, # Boolean flag
            acm_a=ACM_A, acm_b=ACM_B
        )
        if final_decrypted_image is None:
             print("Decryption process failed to produce final image.")
             # Mark overall success as false if final decryption step fails
             integrity_check_passed = False

    else:
        # Ensure final_decrypted_image is None if skipping or if previous steps failed
        print("\nSkipping Decryption.")
        final_decrypted_image = None


    # --- Step 7: Performance & Security Analysis ---
    print("\n--- Task 7: Performance & Security Analysis ---")
    print("\n--- Timing ---")
    print(f"Encryption Time:   {encryption_time:.4f}s")
    print(f"Compression Time:  {compression_time:.4f}s")
    print(f"Decompression Time:{decompression_time:.4f}s")
    print(f"Decryption Time:   {decryption_time:.4f}s")
    total_time = encryption_time + compression_time + decompression_time + decryption_time
    print(f"Total Time (Enc->Comp->Decomp->Dec): {total_time:.4f}s")
    if original_image_padded is not None:
         print(f"Image dimensions processed (padded): {original_image_padded.shape}")
    if original_image_unpadded is not None:
         print(f"Original unpadded dimensions: {original_image_unpadded.shape}")

    print("\n--- Similarity Metrics (Original Unpadded vs Final Decrypted) ---")
    # Check both integrity_check_passed AND if final_decrypted_image is valid
    if integrity_check_passed and final_decrypted_image is not None:
        # Compare the final result with the *original unpadded* image
        metrics_decrypted = calculate_metrics(original_image_unpadded, final_decrypted_image)
        print(f"MSE:  {metrics_decrypted.get('mse', 'N/A'):.4f}")
        # Handle potential infinity PSNR for perfect reconstruction
        psnr_val = metrics_decrypted.get('psnr', 0)
        psnr_str = f"{psnr_val:.4f} dB" if np.isfinite(psnr_val) else "inf (Perfect Reconstruction)"
        print(f"PSNR: {psnr_str}")
        print(f"SSIM: {metrics_decrypted.get('ssim', 'N/A'):.4f}")
        print(f"Entropy (Original):  {metrics_decrypted.get('entropy_orig', 'N/A'):.4f}")
        print(f"Entropy (Decrypted): {metrics_decrypted.get('entropy_proc', 'N/A'):.4f}")

        # Add a clearer success message based on metrics
        if metrics_decrypted.get('mse', 1) < 1e-6: # Check if MSE is near zero
             print("\nMetrics suggest Decryption SUCCESSFUL (Low MSE, High PSNR/SSIM).")
        else:
             print("\nWarning: Metrics indicate differences between original and decrypted images.")
    else:
        print("Skipping decrypted metrics calculation (Integrity check failed or decryption error).")
        # Calculate original entropy anyway if possible
        if original_image_unpadded is not None:
             try:
                  print(f"Entropy (Original):  {shannon_entropy(original_image_unpadded):.4f}")
             except Exception as e:
                  print(f"Could not calculate original entropy: {e}")


    print("\n--- Security Analysis (Original Unpadded vs Encrypted Padded) ---")
    # Compare original unpadded entropy vs encrypted (padded) entropy
    if original_image_unpadded is not None and encrypted_image is not None:
         try:
              entropy_original = shannon_entropy(original_image_unpadded)
              entropy_encrypted = shannon_entropy(encrypted_image) # Analyze the encrypted image before compression
              print(f"Entropy (Original Unpadded): {entropy_original:.4f}")
              print(f"Entropy (Encrypted Padded):  {entropy_encrypted:.4f}")
              # Check if entropy increased significantly and approaches max (8 for uint8)
              ideal_entropy = 8.0 * (np.log2(256) / 8.0) # Ideal entropy for uint8 is 8.0
              entropy_diff = entropy_encrypted - entropy_original
              if entropy_diff > 0.5 and abs(entropy_encrypted - ideal_entropy) < 0.5:
                  print("Entropy increased significantly towards ideal random distribution (Good).")
              elif entropy_diff > 0.1:
                  print("Entropy increased after encryption (Okay).")
              else:
                  print("Warning: Entropy did not increase significantly after encryption. Encryption might be weak or ineffective.")
         except Exception as e:
              print(f"Could not perform entropy analysis: {e}")
    else:
         print("Cannot perform entropy comparison (missing original or encrypted image).")


    print("\n--- Histograms & Image Display ---")
    # Display original (unpadded), encrypted (padded), decrypted (final unpadded)
    # Pass None carefully if steps failed
    plot_histograms(original_image_unpadded,
                    encrypted_image,
                    final_decrypted_image if integrity_check_passed else None)
    display_images(original_image_unpadded,
                   encrypted_image,
                   final_decrypted_image if integrity_check_passed else None)


    # --- Key Sensitivity Test (Example) ---
    print("\n--- Key Sensitivity Test ---")
    # Rerun decryption with a slightly wrong key
    # Requires the correctly decompressed data from Step 5
    if integrity_check_passed and decompressed_encrypted_image is not None:
        # Introduce a tiny change to one key parameter
        # Ensure the change is significant enough given float precision
        wrong_logistic_x0 = LOGISTIC_X0 + 1e-7 # Minimal change
        print(f"Attempting decryption with slightly modified key (x0 = {wrong_logistic_x0})...")

        # Perform only the decryption step with the wrong key
        decrypted_wrong_key, _ = decrypt_image(
            decompressed_encrypted_image, # Use the correctly decompressed data
            ACM_ITERATIONS,
            wrong_logistic_x0, # <<< Use wrong key here
            LOGISTIC_R,
            original_size_before_padding, was_padded, ACM_A, ACM_B
            )

        if decrypted_wrong_key is not None:
            # Compare the wrongly decrypted result to the original unpadded image
            metrics_wrong = calculate_metrics(original_image_unpadded, decrypted_wrong_key)
            print(f"Resulting PSNR (Wrong Key): {metrics_wrong.get('psnr', 0):.4f} dB")
            print(f"Resulting SSIM (Wrong Key): {metrics_wrong.get('ssim', 0):.4f}")
            # Expect very low PSNR and SSIM if sensitive
            if metrics_wrong.get('psnr', 100) < 15 and metrics_wrong.get('ssim', 1) < 0.1:
                print("Key sensitivity test PASSED: Decryption with slightly wrong key produced significantly different result.")
            else:
                print("Key sensitivity test FAILED: Decryption with slightly wrong key did not produce a significantly different result (PSNR/SSIM too high). Check algorithm/parameters.")
            # Optional: Display wrongly decrypted image
            # plt.figure(); plt.imshow(decrypted_wrong_key, cmap='gray' if decrypted_wrong_key.ndim==2 else None); plt.title('Decrypted with Slightly Wrong Key'); plt.axis('off'); plt.show()
        else:
            print("Decryption with wrong key failed to produce an image for comparison.")
    else:
        print("Skipping key sensitivity test (Integrity check failed or decompressed data unavailable).")


    # --- Step 8: Save & Download Output ---
    print("\n--- Task 8: Saving and Downloading Output ---")

    # Save the COMPRESSED ENCRYPTED data
    if compressed_encrypted_data is not None:
        try:
            with open(COMPRESSED_ENCRYPTED_FILENAME, "wb") as f:
                f.write(compressed_encrypted_data)
            print(f"Compressed encrypted data saved as: {COMPRESSED_ENCRYPTED_FILENAME}")
        except Exception as e:
            print(f"Error saving compressed encrypted data: {e}")
    else:
        print("Compressed encrypted data not available to save.")

    # Save the FINAL DECRYPTED image (if successful)
    dec_img_pil = None
    # Check integrity_check_passed AND if final_decrypted_image is a valid array
    if integrity_check_passed and final_decrypted_image is not None:
        try:
            dec_img_pil = Image.fromarray(final_decrypted_image)
            dec_img_pil.save(DECRYPTED_FILENAME)
            print(f"Final decrypted image saved as: {DECRYPTED_FILENAME}")
        except Exception as e:
            print(f"Error saving decrypted image: {e}")
            # Ensure dec_img_pil is None if saving fails
            dec_img_pil = None
    else:
         print("Final decrypted image not saved (Integrity check failed or decryption error).")

    # --- Trigger Download ---
    if ENV == 'colab':
        print("Initiating Colab downloads (if files were saved)...")
        # Check if file exists before attempting download
        if os.path.exists(COMPRESSED_ENCRYPTED_FILENAME):
             try:
                  files.download(COMPRESSED_ENCRYPTED_FILENAME)
             except Exception as e:
                  print(f"Colab download failed for {COMPRESSED_ENCRYPTED_FILENAME}: {e}")
        # Check if decrypted image was saved before attempting download
        if dec_img_pil is not None and os.path.exists(DECRYPTED_FILENAME):
             try:
                  files.download(DECRYPTED_FILENAME)
             except Exception as e:
                  print(f"Colab download failed for {DECRYPTED_FILENAME}: {e}")

    elif ENV == 'jupyter':
        print("Generating Jupyter download links (if files were saved)...")
        links_html = []
        # Link for compressed data
        if compressed_encrypted_data is not None:
            link1 = create_download_link_jupyter(
                COMPRESSED_ENCRYPTED_FILENAME,
                compressed_encrypted_data, # Pass bytes directly
                f"Download Compressed Encrypted Data ({COMPRESSED_ENCRYPTED_FILENAME})",
                'application/zlib' # More specific MIME type for zlib data
             )
            if link1: links_html.append(link1) # Add only if link created

        # Link for decrypted image - Read the saved file back into bytes
        if dec_img_pil is not None and os.path.exists(DECRYPTED_FILENAME):
             try:
                 with open(DECRYPTED_FILENAME, "rb") as f:
                     dec_png_bytes = f.read()
                 link2 = create_download_link_jupyter(
                     DECRYPTED_FILENAME,
                     dec_png_bytes, # Pass file bytes
                     f"Download Decrypted Image ({DECRYPTED_FILENAME})",
                     'image/png' # Specific MIME type
                 )
                 if link2: links_html.append(link2) # Add only if link created
             except Exception as e:
                  print(f"Could not read decrypted PNG file for download link: {e}")

        if links_html:
             display(HTML("<br>".join(links_html))) # Display links in output
        else:
             print("No files available for download link generation.")

    else: # 'other' environment
        print("\nOutput Files (if saved):")
        if os.path.exists(COMPRESSED_ENCRYPTED_FILENAME):
             print(f"- Compressed encrypted data: {os.path.abspath(COMPRESSED_ENCRYPTED_FILENAME)}")
        if dec_img_pil is not None and os.path.exists(DECRYPTED_FILENAME):
             print(f"- Final decrypted image: {os.path.abspath(DECRYPTED_FILENAME)}")
        print("(Manual download/retrieval required if not in Colab/Jupyter)")


# <<<< ****** START OF THE MAIN EXCEPT BLOCK ****** >>>>
except Exception as e:
    # This block catches any unhandled error from the 'try' block above
    print(f"\n--- AN UNHANDLED ERROR OCCURRED IN THE MAIN PIPELINE ---")
    # Print detailed traceback
    print(f"Error Type: {type(e).__name__}")
    print(f"Error Message: {e}")
    print("Traceback:")
    traceback.print_exc() # Print the full traceback to help debugging
    print("\n--- Pipeline Halted Due to Error ---")


# <<<< ****** START OF THE MAIN FINALLY BLOCK ****** >>>>
finally:
    # This block runs *always*, whether the try block succeeded or failed
    # Optional: Clean up temporary saved files?
    # Usually better to leave them for inspection after execution.
    # if os.path.exists(COMPRESSED_ENCRYPTED_FILENAME):
    #     try: os.remove(COMPRESSED_ENCRYPTED_FILENAME)
    #     except OSError as e: print(f"Could not remove temp file {COMPRESSED_ENCRYPTED_FILENAME}: {e}")
    # if os.path.exists(DECRYPTED_FILENAME):
    #     try: os.remove(DECRYPTED_FILENAME)
    #     except OSError as e: print(f"Could not remove temp file {DECRYPTED_FILENAME}: {e}")

    # Signal completion
    print("\n--- Image Processing Script Execution Finished ---")

